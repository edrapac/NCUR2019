{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import seaborn as sb\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maciek2552</th>\n",
       "      <th>maciek2552.1</th>\n",
       "      <th>5/5/1991</th>\n",
       "      <th>maciek2552.2</th>\n",
       "      <th>100.000</th>\n",
       "      <th>100.000.1</th>\n",
       "      <th>20.000</th>\n",
       "      <th>73.334</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>money3</td>\n",
       "      <td>money3</td>\n",
       "      <td>12/31/1969</td>\n",
       "      <td>money3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12.500</td>\n",
       "      <td>70.834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>money6</td>\n",
       "      <td>money6</td>\n",
       "      <td>2/21/1986</td>\n",
       "      <td>money6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12.500</td>\n",
       "      <td>70.834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>money7</td>\n",
       "      <td>money7</td>\n",
       "      <td>2/24/1957</td>\n",
       "      <td>money7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12.500</td>\n",
       "      <td>70.834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wwide2008</td>\n",
       "      <td>wwide2008</td>\n",
       "      <td>1/1/1983</td>\n",
       "      <td>wwide2008</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.527</td>\n",
       "      <td>70.176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jmamian</td>\n",
       "      <td>jmamian</td>\n",
       "      <td>2/26/1981</td>\n",
       "      <td>jmamian</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>66.667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  maciek2552 maciek2552.1    5/5/1991 maciek2552.2  100.000  100.000.1  \\\n",
       "0     money3       money3  12/31/1969       money3    100.0      100.0   \n",
       "1     money6       money6   2/21/1986       money6    100.0      100.0   \n",
       "2     money7       money7   2/24/1957       money7    100.0      100.0   \n",
       "3  wwide2008    wwide2008    1/1/1983    wwide2008    100.0      100.0   \n",
       "4    jmamian      jmamian   2/26/1981      jmamian    100.0      100.0   \n",
       "\n",
       "   20.000  73.334  0  \n",
       "0  12.500  70.834  0  \n",
       "1  12.500  70.834  0  \n",
       "2  12.500  70.834  0  \n",
       "3  10.527  70.176  0  \n",
       "4   0.000  66.667  0  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'random_sampling(1-10000).csv'\n",
    "users = pd.read_csv(data)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>dob</th>\n",
       "      <th>password</th>\n",
       "      <th>firstname_similarity</th>\n",
       "      <th>lastname_similarity</th>\n",
       "      <th>dob_similarity</th>\n",
       "      <th>aggregate_similarity</th>\n",
       "      <th>strength_aggregate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>money3</td>\n",
       "      <td>money3</td>\n",
       "      <td>12/31/1969</td>\n",
       "      <td>money3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12.500</td>\n",
       "      <td>70.834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>money6</td>\n",
       "      <td>money6</td>\n",
       "      <td>2/21/1986</td>\n",
       "      <td>money6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12.500</td>\n",
       "      <td>70.834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>money7</td>\n",
       "      <td>money7</td>\n",
       "      <td>2/24/1957</td>\n",
       "      <td>money7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12.500</td>\n",
       "      <td>70.834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wwide2008</td>\n",
       "      <td>wwide2008</td>\n",
       "      <td>1/1/1983</td>\n",
       "      <td>wwide2008</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.527</td>\n",
       "      <td>70.176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jmamian</td>\n",
       "      <td>jmamian</td>\n",
       "      <td>2/26/1981</td>\n",
       "      <td>jmamian</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>66.667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   firstname   lastname         dob   password  firstname_similarity  \\\n",
       "0     money3     money3  12/31/1969     money3                 100.0   \n",
       "1     money6     money6   2/21/1986     money6                 100.0   \n",
       "2     money7     money7   2/24/1957     money7                 100.0   \n",
       "3  wwide2008  wwide2008    1/1/1983  wwide2008                 100.0   \n",
       "4    jmamian    jmamian   2/26/1981    jmamian                 100.0   \n",
       "\n",
       "   lastname_similarity  dob_similarity  aggregate_similarity  \\\n",
       "0                100.0          12.500                70.834   \n",
       "1                100.0          12.500                70.834   \n",
       "2                100.0          12.500                70.834   \n",
       "3                100.0          10.527                70.176   \n",
       "4                100.0           0.000                66.667   \n",
       "\n",
       "   strength_aggregate  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.columns = ['firstname','lastname','dob','password',\n",
    "                'firstname_similarity','lastname_similarity',\n",
    "                'dob_similarity','aggregate_similarity',\n",
    "                'strength_aggregate']\n",
    "users.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>dob</th>\n",
       "      <th>password</th>\n",
       "      <th>firstname_similarity</th>\n",
       "      <th>lastname_similarity</th>\n",
       "      <th>dob_similarity</th>\n",
       "      <th>aggregate_similarity</th>\n",
       "      <th>strength_aggregate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9004</th>\n",
       "      <td>Frank</td>\n",
       "      <td>McMillon</td>\n",
       "      <td>1/23/1967</td>\n",
       "      <td>Mr_Mack**</td>\n",
       "      <td>28.572</td>\n",
       "      <td>23.530</td>\n",
       "      <td>0.000</td>\n",
       "      <td>17.368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4847</th>\n",
       "      <td>mallibabu</td>\n",
       "      <td>emani</td>\n",
       "      <td>8/10/1960</td>\n",
       "      <td>lali9likki</td>\n",
       "      <td>20.000</td>\n",
       "      <td>26.667</td>\n",
       "      <td>10.000</td>\n",
       "      <td>26.258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8139</th>\n",
       "      <td>James</td>\n",
       "      <td>green</td>\n",
       "      <td>12/1/1981</td>\n",
       "      <td>cigna187</td>\n",
       "      <td>11.765</td>\n",
       "      <td>30.770</td>\n",
       "      <td>23.530</td>\n",
       "      <td>22.022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>Ranjith</td>\n",
       "      <td>Rabel</td>\n",
       "      <td>6/19/1956</td>\n",
       "      <td>anj1956</td>\n",
       "      <td>90.910</td>\n",
       "      <td>16.667</td>\n",
       "      <td>47.059</td>\n",
       "      <td>35.528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>shamsul</td>\n",
       "      <td>hj hashim</td>\n",
       "      <td>1/9/1970</td>\n",
       "      <td>700109</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>28.572</td>\n",
       "      <td>9.524</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      firstname   lastname        dob    password  firstname_similarity  \\\n",
       "9004      Frank   McMillon  1/23/1967   Mr_Mack**                28.572   \n",
       "4847  mallibabu      emani  8/10/1960  lali9likki                20.000   \n",
       "8139      James      green  12/1/1981    cigna187                11.765   \n",
       "1487    Ranjith      Rabel  6/19/1956     anj1956                90.910   \n",
       "5979    shamsul  hj hashim   1/9/1970      700109                 0.000   \n",
       "\n",
       "      lastname_similarity  dob_similarity  aggregate_similarity  \\\n",
       "9004               23.530           0.000                17.368   \n",
       "4847               26.667          10.000                26.258   \n",
       "8139               30.770          23.530                22.022   \n",
       "1487               16.667          47.059                35.528   \n",
       "5979                0.000          28.572                 9.524   \n",
       "\n",
       "      strength_aggregate  \n",
       "9004                   1  \n",
       "4847                   1  \n",
       "8139                   1  \n",
       "1487                   0  \n",
       "5979                   1  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample=users.sample(n=5000)\n",
    "test_sample=users.sample(n=3500)\n",
    "train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Axiom\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Axiom\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Axiom\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n",
      "C:\\Users\\Axiom\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "user_train_data = train_sample.ix[:,(4,5,6)].values # selects features (independent vars fname similarity,lname similarity,dob similarity,aggregate password similarity)\n",
    "user_train_data_names = ['firstname_similarity','lastname_similarity',\n",
    "                  'dob_similarity'] #names the above features\n",
    "y1 = train_sample.ix[:,8].values #our target variable (password strength)\n",
    "user_test_data = test_sample.ix[:,(4,5,6)].values\n",
    "user_train_data_names = ['firstname_similarity','lastname_similarity',\n",
    "                  'dob_similarity']\n",
    "y2 = test_sample.ix[:,8].values\n",
    "#Please note that using .ix will throw a deprecation warning, it should still work fine however"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "firstname               1\n",
       "lastname                1\n",
       "dob                     0\n",
       "password                0\n",
       "firstname_similarity    0\n",
       "lastname_similarity     0\n",
       "dob_similarity          0\n",
       "aggregate_similarity    0\n",
       "strength_aggregate      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.isnull().sum() #just checks to make sure there is no null vals\n",
    "#should return all 0's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname_similarity</th>\n",
       "      <th>lastname_similarity</th>\n",
       "      <th>dob_similarity</th>\n",
       "      <th>aggregate_similarity</th>\n",
       "      <th>strength_aggregate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.890868</td>\n",
       "      <td>32.622557</td>\n",
       "      <td>12.196937</td>\n",
       "      <td>27.950997</td>\n",
       "      <td>0.646000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.097819</td>\n",
       "      <td>20.204854</td>\n",
       "      <td>15.545547</td>\n",
       "      <td>8.320693</td>\n",
       "      <td>0.478257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>17.392000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.576000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.295000</td>\n",
       "      <td>30.770000</td>\n",
       "      <td>9.524000</td>\n",
       "      <td>27.778000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>42.858000</td>\n",
       "      <td>22.223000</td>\n",
       "      <td>32.593000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>88.889000</td>\n",
       "      <td>70.176000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       firstname_similarity  lastname_similarity  dob_similarity  \\\n",
       "count           5000.000000          5000.000000     5000.000000   \n",
       "mean              38.890868            32.622557       12.196937   \n",
       "std               22.097819            20.204854       15.545547   \n",
       "min                0.000000             0.000000        0.000000   \n",
       "25%               25.000000            17.392000        0.000000   \n",
       "50%               35.295000            30.770000        9.524000   \n",
       "75%               50.000000            42.858000       22.223000   \n",
       "max              100.000000           100.000000       88.889000   \n",
       "\n",
       "       aggregate_similarity  strength_aggregate  \n",
       "count           5000.000000         5000.000000  \n",
       "mean              27.950997            0.646000  \n",
       "std                8.320693            0.478257  \n",
       "min                0.000000            0.000000  \n",
       "25%               22.576000            0.000000  \n",
       "50%               27.778000            1.000000  \n",
       "75%               32.593000            1.000000  \n",
       "max               70.176000            1.000000  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29fa74cb588>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.countplot(x='strength_aggregate',data=train_sample,palette='hls') \n",
    "#check distribution of the data. 0's are bad 1's are good \n",
    "# as of 3/21 we have about a 40/60 split of 0's and 1's respectively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = scale(user_train_data)\n",
    "X2 = scale(user_test_data)#scales data so all attributes are of same scale \n",
    "#throws out data that is of magnitudes greater than the other data in the set \n",
    "#essentially removes outliers\n",
    "\n",
    "#lab_enc = preprocessing.LabelEncoder()\n",
    "#encoded = lab_enc.fit_transform(y) \n",
    "\n",
    "# the above is needd because for whatever reason the 1's and 0's\n",
    "# of the training score are being interpreted as floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Axiom\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.837"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(X1,y1) #fits model on training set \n",
    "LogReg.score(X1,y1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.68      0.74       351\n",
      "           1       0.84      0.92      0.88       649\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      1000\n",
      "   macro avg       0.83      0.80      0.81      1000\n",
      "weighted avg       0.84      0.84      0.83      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = LogReg.predict(X1) #given the features, what would this algorithm predict\n",
    "from sklearn.metrics import classification_report # the way to display that classification\n",
    "print(classification_report(y1,y_pred)) # will print the actual value (good or bad) next to what the algorithm thinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
